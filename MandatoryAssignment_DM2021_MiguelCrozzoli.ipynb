{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e41bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random #for kmeans random selection of first mean within the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0751db22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\migue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\yosoy\\\\Documents\\\\ITU _ DATA MINING\\\\Mandatory assigment 1\\\\Dataminers_2021H2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20596/2499838157.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\yosoy\\Documents\\ITU _ DATA MINING\\Mandatory assigment 1\\Dataminers_2021H2.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\yosoy\\\\Documents\\\\ITU _ DATA MINING\\\\Mandatory assigment 1\\\\Dataminers_2021H2.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\yosoy\\Documents\\ITU _ DATA MINING\\Mandatory assigment 1\\Dataminers_2021H2.csv', ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = 'Timestamp') #remove TimeStamp as it's not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just checking data tyopes\n",
    "print(type(df))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f175cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking odd inputs and converting from cm or feet to inches. If input is nul, replace it with mean\n",
    "for x in range(len(df['Your height (in International inches)'])):\n",
    "    if df['Your height (in International inches)'][x] > 80:\n",
    "        df['Your height (in International inches)'][x] = df['Your height (in International inches)'][x]*0.3937\n",
    "    if df['Your height (in International inches)'][x] < 10:\n",
    "        df['Your height (in International inches)'][x] = df['Your height (in International inches)'][x]*12\n",
    "    if df['Your height (in International inches)'][x] == 0:\n",
    "        df['Your height (in International inches)'][x] = df['Your height (in International inches)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca8a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#formating float for clarity\n",
    "df['Your height (in International inches)'] = df['Your height (in International inches)'].map('{:.2f}'.format) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0692fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing data type for formating and manipulation\n",
    "df['Shoe'] = df['Shoe'].astype(int)\n",
    "df['Your height (in International inches)'] = df['Your height (in International inches)'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f461bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why are you taking this course? (;) > as we have multiple answers on each input and we are interested on each value\n",
    "#let's create a new dataframe with all the information.\n",
    "#dfWhy = df['Why are you taking this course?']\n",
    "\n",
    "dfWhyTakingCourse = []\n",
    "\n",
    "for x in range(len(df['Why are you taking this course?'])):\n",
    "    dfWhyTakingCourse.append(df['Why are you taking this course?'][x].split(';'))\n",
    "    \n",
    "newDfWhyTakingCourse = []\n",
    "for l in dfWhyTakingCourse:\n",
    "    newDfWhyTakingCourse.append([x.split(',') for x in l]) \n",
    "\n",
    "flat_list = []\n",
    "for sublist in newDfWhyTakingCourse:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "        \n",
    "df2 = flat_list\n",
    "df2 = pd.DataFrame(df2)\n",
    "\n",
    "df2['Why Taking This Course'] = df2[0]\n",
    "df2 = df2.drop([0, 1], axis=1)\n",
    "\n",
    "#df2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3672e67",
   "metadata": {},
   "source": [
    "# at the moment I have two DataFrames to work with: df and df2\n",
    "#Lets plot them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfc5b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Shoe'].plot(kind='hist', bins=10) #bins=[35, 37, 39, 41, 43, 45, 47])\n",
    "plt.xlabel('Shoe size')\n",
    "plt.axvline(df['Shoe'].mean(), color='red', label = 'shoe mean' )\n",
    "print(f\"Shoe mean: {df['Shoe'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f1f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Your height (in International inches)'].plot(kind='hist', color= 'orange', bins=20)\n",
    "plt.xlabel('Height')\n",
    "plt.axvline(df['Your height (in International inches)'].mean(), color='red', label = 'height mean' )\n",
    "print(f\"Height mean: {df['Your height (in International inches)'].mean()}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "463209c3",
   "metadata": {},
   "source": [
    "#it seems that there is an imput lower than 60 that doesn't fit to our data set... delete it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Which programme are you studying?'].value_counts().plot(kind='bar', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Why Taking This Course'].value_counts().plot(kind='barh', color='green')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec22d824",
   "metadata": {},
   "source": [
    "# the last two+two items on 'why this subject' seem redundant... change/merge? !!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d907b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing Data for kmeans interpretation (?) just in case on a different df\n",
    "dfKmeans1 = df.copy()\n",
    "#dfKmeans1['Shoe'] = dfKmeans1['Shoe']/max(dfKmeans1['Shoe'])\n",
    "#dfKmeans1['Your height (in International inches)'] = dfKmeans1['Your height (in International inches)'] / max(dfKmeans1['Your height (in International inches)']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c7bbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#and what about the relation between Which program are you studying and Why are you taking this course?\n",
    "#I will create a DataFrame where every answer from Why becomes an element, and copy for each element wich program\n",
    "#is the student studying to create a proper relation for each data point.\n",
    "df3 =[]\n",
    "df3 = pd.DataFrame(df3)\n",
    "dfToAppend = pd.DataFrame(newDfWhyTakingCourse) #to merge with main dataframe\n",
    "df3 = pd.concat([df, dfToAppend], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e95f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(df3[1][1]) #Which type is my element called None?\n",
    "for x in range(5):\n",
    "    for y in range(len(df3)):\n",
    "        if type(df3[x][y]) != list:\n",
    "            df3[x][y] = 0 #easier to operate with value 0\n",
    "\n",
    "#df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a4b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfKmeans2 =[[],[]]\n",
    "\n",
    "for x in range(5):\n",
    "    for y in range(len(df3)):\n",
    "        if df3[x][y] != 0:\n",
    "            dfKmeans2[0].append(df3['Which programme are you studying?'][y])\n",
    "            dfKmeans2[1].append(df3[x][y])\n",
    "\n",
    "dfKmeans2 = pd.DataFrame(dfKmeans2)\n",
    "dfKmeans2 = np.transpose(dfKmeans2)\n",
    "\n",
    "dfKmeans2 = dfKmeans2.rename({0: 'Which programme are you studying?', 1: 'Why are you taking this course?'}, axis=1)\n",
    "dfKmeans2['Why are you taking this course?'] = dfKmeans2['Why are you taking this course?'].astype(str)\n",
    "\n",
    "#chars_to_remove = str('[\"', '\"]', \"['\", \"']\")\n",
    "#dfKmeans2.iloc[row]\n",
    "for row in range(len(dfKmeans2['Why are you taking this course?'])):\n",
    "    dfKmeans2['Why are you taking this course?'][row] = dfKmeans2['Why are you taking this course?'][row].replace('[\"', '')\n",
    "    dfKmeans2['Why are you taking this course?'][row] = dfKmeans2['Why are you taking this course?'][row].replace('\"]', '')\n",
    "    dfKmeans2['Why are you taking this course?'][row] = dfKmeans2['Why are you taking this course?'][row].replace(\"['\", '')\n",
    "    dfKmeans2['Why are you taking this course?'][row] = dfKmeans2['Why are you taking this course?'][row].replace(\"']\", '')\n",
    "    dfKmeans2['Why are you taking this course?'][row] = dfKmeans2['Why are you taking this course?'][row].replace('\"', '')\n",
    "    dfKmeans2['Why are you taking this course?'][row] = dfKmeans2['Why are you taking this course?'][row].replace(\"specialization\", 'Specialization track')\n",
    "    dfKmeans2['Why are you taking this course?'][row] = dfKmeans2['Why are you taking this course?'][row].replace(\"Business skills in terms of having the ability to interpret data and the insights gotten out of it\", \"It'll give me business skills\")\n",
    "    dfKmeans2['Why are you taking this course?'][row] = dfKmeans2['Why are you taking this course?'][row].replace(\"complements modern AI', ' hopefully\", 'as a compliment to AI')\n",
    "    dfKmeans2['Why are you taking this course?'][row] = dfKmeans2['Why are you taking this course?'][row].replace(\"I was a TA in ITU and decised to take some course here since I like your University\", 'I was a TA in ITU')\n",
    "\n",
    "#dfKmeans2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c06ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the plot\n",
    "#dfKmeans2\n",
    "dfKmeans2.value_counts().plot(kind='barh', color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f3d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some extra organization for the why behind each program\n",
    "dfSoftwareDesign = [[],[]]\n",
    "dfMscEsewhere = [[],[]]\n",
    "\n",
    "for element in range(len(dfKmeans2['Which programme are you studying?'])):\n",
    "    if dfKmeans2['Which programme are you studying?'][element] == \"MSc Software Design, ITU\":\n",
    "        dfSoftwareDesign[0].append(dfKmeans2['Which programme are you studying?'][element])\n",
    "        dfSoftwareDesign[1].append(dfKmeans2['Why are you taking this course?'][element])\n",
    "    else:\n",
    "        dfMscEsewhere[0].append(dfKmeans2['Which programme are you studying?'][element])\n",
    "        dfMscEsewhere[1].append(dfKmeans2['Why are you taking this course?'][element])\n",
    "        \n",
    "dfSoftwareDesign = pd.DataFrame(dfSoftwareDesign)\n",
    "dfMscEsewhere = pd.DataFrame(dfMscEsewhere)\n",
    "dfSoftwareDesign = np.transpose(dfSoftwareDesign)\n",
    "dfMscEsewhere = np.transpose(dfMscEsewhere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7df87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that plot\n",
    "dfMscEsewhere[1].value_counts().plot(kind='barh')\n",
    "plt.title('MScElsewhere')\n",
    "plt.show()\n",
    "dfSoftwareDesign[1].value_counts().plot(kind='barh')\n",
    "plt.title('MScITU')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2695da4f",
   "metadata": {},
   "source": [
    "# DATA READY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e28a8c",
   "metadata": {},
   "source": [
    "## Let's start with > Unsupervised > K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a8c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is there a relation between shoe size and height?\n",
    "plt.title('Scatter plot of the Distribution of data of Shoe and Height')\n",
    "plt.scatter(dfKmeans1['Shoe'], dfKmeans1['Your height (in International inches)'])\n",
    "plt.xlabel('Shoe size')\n",
    "plt.ylabel('Height')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40c3292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this one is not saying much\n",
    "plt.title('Scatter plot of the Distribution of data of Program and Why')\n",
    "plt.scatter(dfKmeans2['Which programme are you studying?'], dfKmeans2['Why are you taking this course?'])\n",
    "plt.xlabel('Which Program')\n",
    "plt.ylabel('Why Course')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83147742",
   "metadata": {},
   "source": [
    "# shoe and height data on KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b9f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfKmeans1['class'] = 1 #for mean assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f26a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing two random centers to make the first distance calculations\n",
    "def initializeMeans(dataf):\n",
    "    means = [random.randint(0,len(dataf)), random.randint(0,len(dataf))] \n",
    "    mean1 = dataf.iloc[means[0]]\n",
    "    mean2 = dataf.iloc[means[1]]\n",
    "    return mean1, mean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b349b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#claculate the euclidean distance to both centers and change the classification to 1 or 2, depending the shortest distance\n",
    "def euclideanDist(dataf,pointIDX,mean1,mean2):\n",
    "    point = dataf.iloc[pointIDX]\n",
    "    dist1 = np.sqrt(((float(point[\"Shoe\"])-float(mean1[\"Shoe\"]))**2 + (float(point[\"Your height (in International inches)\"])-float(mean1[\"Your height (in International inches)\"]))**2 ))\n",
    "    dist2 = np.sqrt(((float(point[\"Shoe\"])-float(mean2[\"Shoe\"]))**2 + (float(point[\"Your height (in International inches)\"])-float(mean2[\"Your height (in International inches)\"]))**2 ))\n",
    "    if dist1 < dist2:\n",
    "        dataf.at[pointIDX,\"class\"] = 1\n",
    "    else:\n",
    "        dataf.at[pointIDX,\"class\"] = 2\n",
    "        \n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9829827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#once sorted out, calculate the new mean in regards of the classification done with eucideanDist function\n",
    "def updateMean(dataf):\n",
    "    mean1 = dataf[dataf[\"class\"] == 1].mean()\n",
    "    mean2 = dataf[dataf[\"class\"] == 2].mean()\n",
    "    \n",
    "    return mean1,mean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function that uses the previous def a number of times (iterations), claculating distance and updating the mean \n",
    "def Kmeans(dataf,iterations):\n",
    "    mean1,mean2 = initializeMeans(dataf)\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "\n",
    "        print(\"Iteration {}/{}\".format(iteration,iterations))\n",
    "        \n",
    "        for i in range(len(dataf)):\n",
    "            dataf = euclideanDist(dataf,i,mean1,mean2)\n",
    "            \n",
    "        mean1,mean2 = updateMean(dataf)\n",
    "        \n",
    "    return dataf, mean1, mean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2216343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfKmeans, mean1, mean2 = Kmeans(dfKmeans1,4) #with 4 itirations seems to find the right clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac195228",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.scatter(dfKmeans.loc[dfKmeans['class'] == 1]['Shoe'],dfKmeans.loc[dfKmeans['class'] == 1]['Your height (in International inches)'],color='g',label='1')  \n",
    "plt.scatter(dfKmeans.loc[dfKmeans['class'] == 2]['Shoe'],dfKmeans.loc[dfKmeans['class'] == 2]['Your height (in International inches)'],color='b',label='2')  \n",
    "                                                                                                            \n",
    "plt.scatter(mean1['Shoe'],mean1['Your height (in International inches)'],s=70,label='mean1',marker='s',color='r')                    \n",
    "plt.scatter(mean2['Shoe'],mean2['Your height (in International inches)'],s=70,label='mean2',marker='s',color='y')                    \n",
    "                                                                                                            \n",
    "plt.legend()                                                                                                \n",
    "plt.show()                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e9774",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1ShoeMax = dfKmeans.loc[dfKmeans['class'] == 1]['Shoe'].max()\n",
    "g1ShoeMin = dfKmeans.loc[dfKmeans['class'] == 1]['Shoe'].min()\n",
    "g1ShoeMean = mean1['Shoe']\n",
    "\n",
    "g1HeightMax = dfKmeans.loc[dfKmeans['class'] == 1]['Your height (in International inches)'].max()\n",
    "g1HeightMin = dfKmeans.loc[dfKmeans['class'] == 1]['Your height (in International inches)'].min()\n",
    "g1HeightMean = mean1['Your height (in International inches)']\n",
    "\n",
    "g2ShoeMax = dfKmeans.loc[dfKmeans['class'] == 2]['Shoe'].max()\n",
    "g2ShoeMin = dfKmeans.loc[dfKmeans['class'] == 2]['Shoe'].min()\n",
    "g2ShoeMean = mean2['Shoe']\n",
    "\n",
    "g2HeightMax = dfKmeans.loc[dfKmeans['class'] == 2]['Your height (in International inches)'].max()\n",
    "g2HeightMin = dfKmeans.loc[dfKmeans['class'] == 2]['Your height (in International inches)'].min()\n",
    "g2HeightMean = mean2['Your height (in International inches)']\n",
    "\n",
    "print('GROUP 1:')\n",
    "print(f'max shoe size: {g1ShoeMax}')\n",
    "print(f'min shoe size: {g1ShoeMin}')\n",
    "print(f'shoe size mean: {g1ShoeMean}')\n",
    "print()\n",
    "print(f'max height size: {g1HeightMax}')\n",
    "print(f'min height size: {g1HeightMin}')\n",
    "print(f'height size mean: {g1HeightMean}')\n",
    "print()\n",
    "print('GROUP 2:')\n",
    "print(f'max shoe size: {g2ShoeMax}')\n",
    "print(f'min shoe size: {g2ShoeMin}')\n",
    "print(f'shoe size mean: {g2ShoeMean}')\n",
    "print()\n",
    "print(f'max height size: {g2HeightMax}')\n",
    "print(f'min height size: {g2HeightMin}')\n",
    "print(f'height size mean: {g2HeightMean}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb5e9ec",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b72afb",
   "metadata": {},
   "source": [
    "Step 1: Separate By Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5611535",
   "metadata": {},
   "source": [
    "First, we need to separate our training data by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad4951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just in case a new DataFrame for Naive Bayes\n",
    "dfNaiveBayes = df.copy()\n",
    "dfNaiveBayes['class'] = 1\n",
    "\n",
    "dfNaiveBayes2 = dfKmeans2.copy()\n",
    "dfNaiveBayes2['class'] = 1\n",
    "\n",
    "#do I need any of the other DataFrames: df2? df3? dfKmeans1? dfKmeans2? dfMscEsewhere? dfSoftwareDesign?\n",
    "#dfNaiveBayes = dfNaiveBayes.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78860016",
   "metadata": {},
   "source": [
    "I would like to predict \"Which program are you taking?\" given the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730cd72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Clasify our existing data\n",
    "def classify_data(dataset):\n",
    "    for i in range(len(dataset)):\n",
    "        class_info = dataset['Which programme are you studying?'][i] #category 1 or 2\n",
    "        if class_info == \"MSc Software Design, ITU\": #which categorization I'm trying to find\n",
    "            dataset['class'][i] = 1\n",
    "        else:\n",
    "            dataset['class'][i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f2e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_by_class(dataset):\n",
    "    classify_data(dataset)\n",
    "    separated_number = {1:[],2:[]}\n",
    "    separated_string = {1:[],2:[]}\n",
    "    \n",
    "    tempDf_num = pd.DataFrame()\n",
    "    tempDf_str = pd.DataFrame()\n",
    "    \n",
    "    for col in dataset.columns:\n",
    "        if type(dataset.iloc[0][col]) != str:\n",
    "            tempDf_num = tempDf_num.append(dataset[col])\n",
    "        else: \n",
    "            tempDf_str = tempDf_str.append(dataset[col])\n",
    "    tempDf_str = tempDf_str.append(dataset['class'])\n",
    "            \n",
    "    tempDf_num = np.transpose(tempDf_num)\n",
    "    tempDf_str = np.transpose(tempDf_str)\n",
    "    \n",
    "    for i in range(len(tempDf_num)):\n",
    "        class_value_n = tempDf_num['class'][i]\n",
    "        if tempDf_num['class'][i] == 1:\n",
    "            separated_number[class_value_n].append(tempDf_num.iloc[i])\n",
    "        else:\n",
    "            separated_number[class_value_n].append(tempDf_num.iloc[i])\n",
    "    \n",
    "    for i in range(len(tempDf_str)):\n",
    "        class_value_s = tempDf_str['class'][i]\n",
    "        if tempDf_str['class'][i] == 1:\n",
    "            separated_string[class_value_s].append(tempDf_str.iloc[i])\n",
    "        else:\n",
    "            separated_string[class_value_s].append(tempDf_str.iloc[i])\n",
    "    \n",
    "    return separated_number, separated_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c8343b",
   "metadata": {},
   "source": [
    "Step 2: Summarize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c1994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate likelihood in categorical data\n",
    "def calculate_likelyhood(dataset):\n",
    "    nouse, separated_string = separate_by_class(dataset)\n",
    "    class1 = pd.DataFrame(separated_string[1])\n",
    "    class2 = pd.DataFrame(separated_string[2])\n",
    "    likelyhood1 = pd.DataFrame()\n",
    "    likelyhood2 = pd.DataFrame()\n",
    "    \n",
    "    value_counts1 = class1['Why are you taking this course?'].value_counts()\n",
    "    val_counts1 = pd.DataFrame(value_counts1)\n",
    "    likelyhood1 = val_counts1.reset_index()\n",
    "    likelyhood1.columns = ['Why', 'count']\n",
    "    \n",
    "    value_counts2 = class2['Why are you taking this course?'].value_counts()\n",
    "    val_counts2 = pd.DataFrame(value_counts2)\n",
    "    likelyhood2 = val_counts2.reset_index()\n",
    "    likelyhood2.columns = ['Why', 'count']\n",
    "    \n",
    "    sumLikelyhood1 = sum(likelyhood1['count'])\n",
    "    sumLikelyhood2 = sum(likelyhood2['count'])\n",
    "    likelyhood1['Likelyhood'] = float(1)\n",
    "    likelyhood2['Likelyhood'] = float(1)\n",
    "    \n",
    "    for row in range(len(likelyhood1['count'])):\n",
    "        likelyhood1['Likelyhood'][row] = likelyhood1['count'][row] / sumLikelyhood1\n",
    "    for row in range(len(likelyhood2['count'])):\n",
    "        likelyhood2['Likelyhood'][row] = likelyhood2['count'][row] / sumLikelyhood2\n",
    "    \n",
    "    likelyhood1 = likelyhood1.drop('count', 1)\n",
    "    likelyhood1 = np.transpose(likelyhood1)\n",
    "    likelyhood1.columns = likelyhood1.iloc[0]\n",
    "    likelyhood1 = likelyhood1.drop(likelyhood1.index[0])\n",
    "    likelyhood1['class'] = 1\n",
    "    \n",
    "    likelyhood2 = likelyhood2.drop('count', 1)\n",
    "    likelyhood2 = np.transpose(likelyhood2)\n",
    "    likelyhood2.columns = likelyhood2.iloc[0]\n",
    "    likelyhood2 = likelyhood2.drop(likelyhood2.index[0])\n",
    "    likelyhood2['class'] = 2\n",
    "    \n",
    "    likelyhoods = pd.concat([likelyhood1, likelyhood2])\n",
    "    \n",
    "    #cols = list(likelyhoods.columns.values) #Make a list of all of the columns in the df\n",
    "    #cols.pop(cols.index('class')) #Remove b from list\n",
    "    #likelyhoods = likelyhoods[cols+['class']] #Create new dataframe with columns in the order you want\n",
    "    \n",
    "    likelyhoods = likelyhoods.fillna(0)\n",
    "    likelyhoods = likelyhoods + 1\n",
    "    likelyhoods['class'] = likelyhoods['class'] -1\n",
    "    \n",
    "    likelyhoods = likelyhoods.set_index('class')\n",
    "    \n",
    "    return likelyhoods #for loop should be create after I concatenate both dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean if colum != string (numerical data)\n",
    "def calculate_mean(dataset):\n",
    "    separated_number, nouse = separate_by_class(dataset)\n",
    "    class1 = pd.DataFrame(separated_number[1])\n",
    "    class2 = pd.DataFrame(separated_number[2])\n",
    "    \n",
    "    mean1 = class1.mean()\n",
    "    mean2 = class2.mean()\n",
    "    \n",
    "    mean1 = pd.DataFrame(mean1)\n",
    "    mean1 = np.transpose(mean1)\n",
    "    mean2 = pd.DataFrame(mean2)\n",
    "    mean2 = np.transpose(mean2)\n",
    "    \n",
    "    mean1['class'] = 1\n",
    "    mean2['class'] = 2\n",
    "    \n",
    "    mean1 = mean1.add_suffix('_mean') #could be improved with a for loop\n",
    "    mean1 = mean1.rename({'class_mean' : 'class'}, axis=1) \n",
    "    mean2 = mean2.add_suffix('_mean')\n",
    "    mean2 = mean2.rename({'class_mean' : 'class'}, axis=1)\n",
    "    \n",
    "    means = pd.concat([mean1,mean2])\n",
    "    means = means.set_index('class')\n",
    "    \n",
    "    return means #mean1, mean2, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate standard deviation\n",
    "def calculate_stdev(dataset):\n",
    "    separated_number, nouse = separate_by_class(dataset)\n",
    "    class1 = pd.DataFrame(separated_number[1])\n",
    "    class2 = pd.DataFrame(separated_number[2])\n",
    "    \n",
    "    stdev1 = class1.std()\n",
    "    stdev2 = class2.std()\n",
    "    \n",
    "    stdev1 = pd.DataFrame(stdev1)\n",
    "    stdev1 = np.transpose(stdev1)\n",
    "    stdev2 = pd.DataFrame(stdev2)\n",
    "    stdev2 = np.transpose(stdev2)\n",
    "    \n",
    "    stdev1['class'] = 1\n",
    "    stdev2['class'] = 2\n",
    "    \n",
    "    stdev1 = stdev1.add_suffix('_stdev') #could be improved with a for loop\n",
    "    stdev1 = stdev1.rename({'class_stdev' : 'class'}, axis=1) \n",
    "    stdev2 = stdev2.add_suffix('_stdev')\n",
    "    stdev2 = stdev2.rename({'class_stdev' : 'class'}, axis=1) \n",
    "    \n",
    "    stdevs = pd.concat([stdev1, stdev2])\n",
    "    stdevs = stdevs.set_index('class')\n",
    "    \n",
    "    return stdevs #stdev1,stdev2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0880d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate probabily between class 1 and 2 of the given dataset #Do I need it??\n",
    "def given_probability(dataset):\n",
    "    nouse, separated_string = separate_by_class(dataset)\n",
    "    class1 = pd.DataFrame(separated_string[1])\n",
    "    class2 = pd.DataFrame(separated_string[2])\n",
    "    givenProb1 = pd.DataFrame()\n",
    "    givenProb2 = pd.DataFrame()\n",
    "    \n",
    "    value_counts1 = class1['Which programme are you studying?'].value_counts()\n",
    "    val_counts1 = pd.DataFrame(value_counts1)\n",
    "    givenProb1 = val_counts1.reset_index()\n",
    "    givenProb1.columns = ['Which', 'count']\n",
    "\n",
    "    value_counts2 = class2['Which programme are you studying?'].value_counts()\n",
    "    val_counts2 = pd.DataFrame(value_counts2)\n",
    "    givenProb2 = val_counts2.reset_index()\n",
    "    givenProb2.columns = ['Which', 'count']\n",
    "    \n",
    "    sumProbs = sum(givenProb1['count'], givenProb2['count'])\n",
    "\n",
    "    givenProb1['Probability'] =  (givenProb1['count']) / sumProbs\n",
    "    givenProb2['Probability'] =  (givenProb2['count']) / sumProbs\n",
    "\n",
    "    givenProb1['class'] = 1\n",
    "    givenProb2['class'] = 2\n",
    "\n",
    "    givenProb1 = givenProb1.drop(columns = ['Which', 'count'])\n",
    "    givenProb2 = givenProb2.drop(columns = ['Which', 'count'])\n",
    "    \n",
    "    givenProbs = pd.concat([givenProb1, givenProb2])\n",
    "    givenProbs = givenProbs.set_index('class')\n",
    "    \n",
    "    return givenProbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700b5a8b",
   "metadata": {},
   "source": [
    "Step 3: Sumarize Data by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2a75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumarize_by_class(dataset1, dataset2): #should correct this preparing better my data\n",
    "    means = calculate_mean(dataset1)\n",
    "    stdevs = calculate_stdev(dataset1)\n",
    "    likelyhoods = calculate_likelyhood(dataset2)\n",
    "    givenProbs = given_probability(dataset1)\n",
    "    \n",
    "    summary = pd.concat([givenProbs, means, stdevs, likelyhoods], axis=1)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00497a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a13746e6",
   "metadata": {},
   "source": [
    "Step 4: Gaussian Probability Density Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11dc4a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Gaussian probability distribution function for x\n",
    "def normal_dist(x, mean, stdev):\n",
    "    normal_d = (np.pi*stdev) * np.exp(-0.5*((x-mean)/stdev)**2)\n",
    "    return normal_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc7730",
   "metadata": {},
   "source": [
    "Step 5: Class Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13fc8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_probabilities(given_dataset1, given_dataset2, dataset_to_calculate):\n",
    "    summary = sumarize_by_class(given_dataset1, given_dataset2)\n",
    "    df_probability_calculated = dataset_to_calculate.copy()\n",
    "    df_probability_calculated['ITU'] = float(1)\n",
    "    df_probability_calculated['Elsewhere'] = float(1)\n",
    "    df_probability_calculated['class'] = 0\n",
    "    \n",
    "    #Probability for MScITU\n",
    "    #class1_prob = summary.iloc[0][0]\n",
    "    for row in range(len(tryDataSet)):\n",
    "        normal_d_shoe = normal_dist(tryDataSet['Shoe'][row], summary['Shoe_mean'][1], summary['Shoe_stdev'][1])\n",
    "        normal_d_hieght = normal_dist(tryDataSet['Your height (in International inches)'][row], summary['Your height (in International inches)_mean'][1], summary['Your height (in International inches)_stdev'][1])\n",
    "        for x in range(len(summary.columns)):\n",
    "            why_likelihood = 1\n",
    "            if tryDataSet['Why?'][row] == summary.columns[x]:\n",
    "                why_likelihood = summary.iloc[0][x]\n",
    "        probability_ITU = normal_d_shoe * normal_d_hieght * why_likelihood #* class1_prob\n",
    "        df_probability_calculated['ITU'][row] = probability_ITU\n",
    "    \n",
    "    #Probability for MScElsewhere\n",
    "    #class2_prob = summary.iloc[1][0]\n",
    "    for row in range(len(dataset_to_calculate)):\n",
    "        normal_d_shoe = normal_dist(dataset_to_calculate['Shoe'][row], summary['Shoe_mean'][2], summary['Shoe_stdev'][2])\n",
    "        normal_d_hieght = normal_dist(dataset_to_calculate['Your height (in International inches)'][row], summary['Your height (in International inches)_mean'][2], summary['Your height (in International inches)_stdev'][2])\n",
    "        for x in range(len(summary.columns)):\n",
    "            why_likelihood = 1\n",
    "            if tryDataSet['Why?'][row] == summary.columns[x]:\n",
    "                why_likelihood = summary.iloc[1][x]\n",
    "        probability_ITU = normal_d_shoe * normal_d_hieght * why_likelihood #* class2_prob \n",
    "        df_probability_calculated['Elsewhere'][row] = probability_ITU\n",
    "    \n",
    "    #writing probability into dataframe's class\n",
    "    for row in range(len(dataset_to_calculate)):\n",
    "        if df_probability_calculated['ITU'][row] > df_probability_calculated['Elsewhere'][row]:\n",
    "            df_probability_calculated['class'][row] = 1\n",
    "        if df_probability_calculated['ITU'][row] < df_probability_calculated['Elsewhere'][row]:\n",
    "            df_probability_calculated['class'][row] = 2\n",
    "        \n",
    "    return df_probability_calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cd9518",
   "metadata": {},
   "source": [
    "# try out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03033067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shoe</th>\n",
       "      <th>Your height (in International inches)</th>\n",
       "      <th>Why?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>61</td>\n",
       "      <td>This was mandatory for me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>70</td>\n",
       "      <td>It is the most exciting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>80</td>\n",
       "      <td>It is the most exciting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>67</td>\n",
       "      <td>Specialization track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>74</td>\n",
       "      <td>The other courses were even less attractive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>69</td>\n",
       "      <td>Specialization track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>Specialization track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39</td>\n",
       "      <td>66</td>\n",
       "      <td>This was mandatory for me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>I was a TA in ITU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Shoe  Your height (in International inches)  \\\n",
       "0    41                                     61   \n",
       "1    32                                     70   \n",
       "2    47                                     80   \n",
       "3    50                                     67   \n",
       "4    39                                     74   \n",
       "5    40                                     69   \n",
       "6    43                                     73   \n",
       "7    39                                     66   \n",
       "8    43                                     73   \n",
       "\n",
       "                                          Why?  \n",
       "0                    This was mandatory for me  \n",
       "1                      It is the most exciting  \n",
       "2                      It is the most exciting  \n",
       "3                         Specialization track  \n",
       "4  The other courses were even less attractive  \n",
       "5                         Specialization track  \n",
       "6                         Specialization track  \n",
       "7                    This was mandatory for me  \n",
       "8                            I was a TA in ITU  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tryDataSet = {'Shoe': [41,32,47,50,39, 40, 43, 39, 43], 'Your height (in International inches)': [61,70,80,67,74, 69, 73, 66, 73], 'Why?':['This was mandatory for me','It is the most exciting','It is the most exciting','Specialization track','The other courses were even less attractive', 'Specialization track', 'Specialization track', 'This was mandatory for me', 'I was a TA in ITU']}\n",
    "tryDataSet = pd.DataFrame(tryDataSet)\n",
    "tryDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "891ba56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-031a8216d045>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['class'][i] = 1\n",
      "<ipython-input-31-031a8216d045>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['class'][i] = 2\n",
      "<ipython-input-33-66f40c13a2ed>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  likelyhood1['Likelyhood'][row] = likelyhood1['count'][row] / sumLikelyhood1\n",
      "<ipython-input-33-66f40c13a2ed>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  likelyhood2['Likelyhood'][row] = likelyhood2['count'][row] / sumLikelyhood2\n",
      "<ipython-input-39-39909885acca>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_probability_calculated['ITU'][row] = probability_ITU\n",
      "<ipython-input-39-39909885acca>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_probability_calculated['Elsewhere'][row] = probability_ITU\n",
      "<ipython-input-39-39909885acca>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_probability_calculated['class'][row] = 1\n",
      "<ipython-input-39-39909885acca>:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_probability_calculated['class'][row] = 2\n"
     ]
    }
   ],
   "source": [
    "df_probability_calculated = calculate_class_probabilities(dfNaiveBayes, dfNaiveBayes2, tryDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b381c520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shoe</th>\n",
       "      <th>Your height (in International inches)</th>\n",
       "      <th>Why?</th>\n",
       "      <th>ITU</th>\n",
       "      <th>Elsewhere</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>61</td>\n",
       "      <td>This was mandatory for me</td>\n",
       "      <td>16.304765</td>\n",
       "      <td>0.182896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>70</td>\n",
       "      <td>It is the most exciting</td>\n",
       "      <td>2.735117</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>80</td>\n",
       "      <td>It is the most exciting</td>\n",
       "      <td>0.523434</td>\n",
       "      <td>2.575265</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>67</td>\n",
       "      <td>Specialization track</td>\n",
       "      <td>1.091154</td>\n",
       "      <td>2.298914</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>74</td>\n",
       "      <td>The other courses were even less attractive</td>\n",
       "      <td>58.290498</td>\n",
       "      <td>49.804684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>69</td>\n",
       "      <td>Specialization track</td>\n",
       "      <td>123.763560</td>\n",
       "      <td>44.425219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>Specialization track</td>\n",
       "      <td>62.761904</td>\n",
       "      <td>102.290345</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39</td>\n",
       "      <td>66</td>\n",
       "      <td>This was mandatory for me</td>\n",
       "      <td>80.149170</td>\n",
       "      <td>8.167229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>I was a TA in ITU</td>\n",
       "      <td>62.761904</td>\n",
       "      <td>108.683491</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Shoe  Your height (in International inches)  \\\n",
       "0    41                                     61   \n",
       "1    32                                     70   \n",
       "2    47                                     80   \n",
       "3    50                                     67   \n",
       "4    39                                     74   \n",
       "5    40                                     69   \n",
       "6    43                                     73   \n",
       "7    39                                     66   \n",
       "8    43                                     73   \n",
       "\n",
       "                                          Why?         ITU   Elsewhere  class  \n",
       "0                    This was mandatory for me   16.304765    0.182896      1  \n",
       "1                      It is the most exciting    2.735117    0.458333      1  \n",
       "2                      It is the most exciting    0.523434    2.575265      2  \n",
       "3                         Specialization track    1.091154    2.298914      2  \n",
       "4  The other courses were even less attractive   58.290498   49.804684      1  \n",
       "5                         Specialization track  123.763560   44.425219      1  \n",
       "6                         Specialization track   62.761904  102.290345      2  \n",
       "7                    This was mandatory for me   80.149170    8.167229      1  \n",
       "8                            I was a TA in ITU   62.761904  108.683491      2  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_probability_calculated"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd9548c7",
   "metadata": {},
   "source": [
    "#Where 1 is 'MSc ITU' and 2 is 'MSc Elsewhere'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ee449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1199cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
